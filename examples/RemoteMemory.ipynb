{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f39cad0-16c4-4ecd-a836-69916596fb3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e69dd0ae-009d-4126-a300-5ef6cfdab9d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-16 15:24:13,433\tINFO worker.py:1538 -- Started a local Ray instance.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <h3 style=\"color: var(--jp-ui-font-color0)\">Ray</h3>\n",
       "        <svg version=\"1.1\" id=\"ray\" width=\"3em\" viewBox=\"0 0 144.5 144.6\" style=\"margin-left: 3em;margin-right: 3em\">\n",
       "            <g id=\"layer-1\">\n",
       "                <path fill=\"#00a2e9\" class=\"st0\" d=\"M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1\n",
       "                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2\n",
       "                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9\n",
       "                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5\n",
       "                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5\n",
       "                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7\n",
       "                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1\n",
       "                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9\n",
       "                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2\n",
       "                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3\n",
       "                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3\n",
       "                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3\n",
       "                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7\n",
       "                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3\n",
       "                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6\n",
       "                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10\n",
       "                    C71.6,134.6,71.7,134.6,71.8,134.6z\"/>\n",
       "            </g>\n",
       "        </svg>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "                <td style=\"text-align: left\"><b>3.9.16</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "                <td style=\"text-align: left\"><b> 2.2.0</b></td>\n",
       "            </tr>\n",
       "            \n",
       "        </table>\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "RayContext(dashboard_url='', python_version='3.9.16', ray_version='2.2.0', ray_commit='b6af0887ee5f2e460202133791ad941a41f15beb', address_info={'node_ip_address': '127.0.0.1', 'raylet_ip_address': '127.0.0.1', 'redis_address': None, 'object_store_address': '/tmp/ray/session_2023-04-16_15-24-11_516899_51546/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2023-04-16_15-24-11_516899_51546/sockets/raylet', 'webui_url': '', 'session_dir': '/tmp/ray/session_2023-04-16_15-24-11_516899_51546', 'metrics_export_port': 60920, 'gcs_address': '127.0.0.1:64017', 'address': '127.0.0.1:64017', 'dashboard_agent_listen_port': 52365, 'node_id': '01214390884dc529d13c6ff80883becea2bd42e94beb8b77f1c6cd81'})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f9efe21e-9399-4bbf-b48f-b9150999cb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate, \n",
    "    MessagesPlaceholder, \n",
    "    SystemMessagePromptTemplate, \n",
    "    HumanMessagePromptTemplate\n",
    ")\n",
    "from langchain import ConversationChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec7a7986-4255-4607-b264-2039f535b4de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca0becb2-7de3-43b2-992b-6710a814816a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatMessageHistory(messages=[])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad7de74-6b84-4fb4-a856-16b10e3c93ca",
   "metadata": {},
   "source": [
    "## ChatMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8500b7c6-81dd-4994-aeb7-2f4cf079d17e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.memory import ChatMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2629aef-29dc-449d-afa0-648878b97c32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = ChatMessageHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e0aa04f-ee77-49b4-9506-135752701066",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history.add_user_message('hi!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdf2e759-eec8-4012-937b-8635611ce1ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='hi!', additional_kwargs={})]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55f34b91-363d-4c9f-a12c-a57a48604f5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history.add_ai_message('My name is Jupyter AI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "895547b2-3637-4f6d-bd75-0b55c2124010",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='hi!', additional_kwargs={}),\n",
       " AIMessage(content='My name is Jupyter AI', additional_kwargs={})]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f63692e-d90f-42d8-b5bb-d3a132c413a0",
   "metadata": {},
   "source": [
    "## ConversationalMemoryBuffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2287be7-7462-4224-9e2a-fec46dbe93b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "960ac73b-3f52-4a0a-a4b7-71fdccf3d368",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b13604d-d2ff-48c3-933e-0411d34159c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "memory.chat_memory.add_user_message('hi')\n",
    "memory.chat_memory.add_ai_message('my name is Jupyter AI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49773d44-5263-447c-a7bf-a62a881f7bc2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: hi\\nAI: my name is Jupyter AI'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2744fa66-88f0-4e8e-b16d-bfb4a05400a3",
   "metadata": {},
   "source": [
    "## Using in a non-chat LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f456ed8e-e265-4a52-9e1d-4107a8c39bea",
   "metadata": {},
   "source": [
    "Here, we are using the `ConversationalMemoryBuffer` with a non-chat LLM. Note that we\n",
    "don't set `return_messages=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a660daa-3a9c-4c7e-9a41-d89ce0f154c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a2befd53-fe03-4b37-918e-be4231b1f756",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5e811b8b-7f7c-4eb5-a896-abcc045643ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory()\n",
    "memory.chat_memory.add_user_message('My name is Brian')\n",
    "memory.chat_memory.add_ai_message('Nice to meet you Brian, how can I help you?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "19441278-8be4-4b7e-9794-aa1fc13e3c55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chain = ConversationChain(\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5b9223f8-b2dd-4315-a8bf-6a6b65277b13",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: My name is Brian\n",
      "AI: Nice to meet you Brian, how can I help you?\n",
      "Human: What is my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' You just told me your name is Brian. Is there anything else I can help you with?'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(input='What is my name?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bca9ddb-3e7a-4e02-8858-8fc0049d7117",
   "metadata": {},
   "source": [
    "Can we set `return_messages=True` and  use the same non-chat chain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7d82cdc4-6a68-4aa9-8e16-eb747ecc752f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: My name is Brian\n",
      "AI: Nice to meet you Brian, how can I help you?\n",
      "Human: What is my name?\n",
      "AI:  You just told me your name is Brian. Is there anything else I can help you with?\n",
      "Human: what is numpy?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Numpy is a Python library used for scientific computing. It contains a powerful N-dimensional array object, useful linear algebra, Fourier transform, and random number capabilities. Is there anything else I can help you with?'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(input='what is numpy?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3aafcfb4-b5d3-4eed-b619-da3104d6adaa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "memory.chat_memory.add_user_message('My name is Brian')\n",
    "memory.chat_memory.add_ai_message('Nice to meet you Brian, how can I help you?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "69224ccc-6f17-43f1-8c8f-14db419fac92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chain = ConversationChain(\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f777fbcf-3e84-4155-a5d4-45596345a9a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "[HumanMessage(content='My name is Brian', additional_kwargs={}), AIMessage(content='Nice to meet you Brian, how can I help you?', additional_kwargs={})]\n",
      "Human: What is my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Your name is Brian.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(input='What is my name?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81881e95-52e3-450b-a7d6-c5c6b314588e",
   "metadata": {},
   "source": [
    "Yes! It seems to be smart enough to handle everything with a non-chat LLM and `return_messages=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f3c53758-d5d9-4b9d-bb51-23afaeed1895",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='My name is Brian', additional_kwargs={}),\n",
       "  AIMessage(content='Nice to meet you Brian, how can I help you?', additional_kwargs={}),\n",
       "  HumanMessage(content='What is my name?', additional_kwargs={}),\n",
       "  AIMessage(content=' Your name is Brian.', additional_kwargs={})]}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "45762088-c86d-48f5-ba61-fef2ddb664b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='My name is Brian', additional_kwargs={}),\n",
       " AIMessage(content='Nice to meet you Brian, how can I help you?', additional_kwargs={}),\n",
       " HumanMessage(content='What is my name?', additional_kwargs={}),\n",
       " AIMessage(content=' Your name is Brian.', additional_kwargs={})]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.chat_memory.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ae788a-5d28-4ba0-88e9-fc3e0c93d026",
   "metadata": {},
   "source": [
    "## Memory actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39a0af80-71f1-440d-a4f0-ac864b426a26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67d66869-6c3e-48bf-bbff-c91b9a2f6955",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-16 21:31:55,633\tINFO worker.py:1538 -- Started a local Ray instance.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <h3 style=\"color: var(--jp-ui-font-color0)\">Ray</h3>\n",
       "        <svg version=\"1.1\" id=\"ray\" width=\"3em\" viewBox=\"0 0 144.5 144.6\" style=\"margin-left: 3em;margin-right: 3em\">\n",
       "            <g id=\"layer-1\">\n",
       "                <path fill=\"#00a2e9\" class=\"st0\" d=\"M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1\n",
       "                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2\n",
       "                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9\n",
       "                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5\n",
       "                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5\n",
       "                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7\n",
       "                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1\n",
       "                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9\n",
       "                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2\n",
       "                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3\n",
       "                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3\n",
       "                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3\n",
       "                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7\n",
       "                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3\n",
       "                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6\n",
       "                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10\n",
       "                    C71.6,134.6,71.7,134.6,71.8,134.6z\"/>\n",
       "            </g>\n",
       "        </svg>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "                <td style=\"text-align: left\"><b>3.9.16</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "                <td style=\"text-align: left\"><b> 2.2.0</b></td>\n",
       "            </tr>\n",
       "            \n",
       "        </table>\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "RayContext(dashboard_url='', python_version='3.9.16', ray_version='2.2.0', ray_commit='b6af0887ee5f2e460202133791ad941a41f15beb', address_info={'node_ip_address': '127.0.0.1', 'raylet_ip_address': '127.0.0.1', 'redis_address': None, 'object_store_address': '/tmp/ray/session_2023-04-16_21-31-53_733102_73188/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2023-04-16_21-31-53_733102_73188/sockets/raylet', 'webui_url': '', 'session_dir': '/tmp/ray/session_2023-04-16_21-31-53_733102_73188', 'metrics_export_port': 65511, 'gcs_address': '127.0.0.1:65179', 'address': '127.0.0.1:65179', 'dashboard_agent_listen_port': 52365, 'node_id': 'c8b392fc1c0329f76161cf460fbb589b664599ba57ad99fa7b91d3ba'})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed7da6e5-0ded-49c8-a2a0-d093af9ee964",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.schema import BaseMemory\n",
    "from typing import Dict, Any, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f1b0d4c-a0b7-489f-a2d1-ee42741dbc66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "class MemoryActor(object):\n",
    "    \n",
    "    def __init__(self, memory):\n",
    "        self.memory = memory\n",
    "    \n",
    "    def get_chat_memory(self):\n",
    "        return self.memory.chat_memory\n",
    "    \n",
    "    def get_output_key(self):\n",
    "        return self.memory.output_key\n",
    "    \n",
    "    def get_input_key(self):\n",
    "        return self.memory.input_key\n",
    "\n",
    "    def get_return_messages(self):\n",
    "        return self.memory.return_messages\n",
    "    \n",
    "    def get_memory_variables(self):\n",
    "        return self.memory.memory_variables\n",
    "\n",
    "    def save_context(self, inputs: Dict[str, Any], outputs: Dict[str, str]) -> None:\n",
    "        return self.memory.save_context(inputs, outputs)\n",
    "    \n",
    "    def clear(self):\n",
    "        return self.memory.clear()\n",
    "    \n",
    "    def load_memory_variables(self, inputs: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        return self.memory.load_memory_variables(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f717a171-3b15-4615-bc0a-a09dfe96db5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pydantic import PrivateAttr\n",
    "\n",
    "class RemoteMemory(BaseMemory):\n",
    "    \n",
    "    actor_name: str\n",
    "    _actor: Any = PrivateAttr()\n",
    "\n",
    "    def __init__(self, **data):\n",
    "        super().__init__(**data)\n",
    "        self._actor = ray.get_actor(self.actor_name)\n",
    "        \n",
    "    @property\n",
    "    def memory_variables(self) -> List[str]:\n",
    "        o = self._actor.get_memory_variables.remote()\n",
    "        return ray.get(o)\n",
    "    \n",
    "    @property\n",
    "    def output_key(self):\n",
    "        o = self._actor.get_output_key.remote()\n",
    "        return ray.get(o)\n",
    "    \n",
    "    @property\n",
    "    def input_key(self):\n",
    "        o = self._actor.get_input_key.remote()\n",
    "        return ray.get(o)\n",
    "    \n",
    "    @property\n",
    "    def return_messages(self):\n",
    "        o = self._actor.get_return_messages.remote()\n",
    "        return ray.get(o)\n",
    "    \n",
    "    def save_context(self, inputs: Dict[str, Any], outputs: Dict[str, str]) -> None:\n",
    "        o = self._actor.save_context.remote(inputs, outputs)\n",
    "        return ray.get(o)\n",
    "    \n",
    "    def clear(self):\n",
    "        self._actor.clear.remote()\n",
    "        \n",
    "    def load_memory_variables(self, inputs: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        o = self._actor.load_memory_variables.remote(inputs)\n",
    "        return ray.get(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "40cb1aa5-cdc9-4b54-9013-334831326d8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory()\n",
    "rmemory = MemoryActor.options(name='m').remote(memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7200e836-231a-46f0-a08e-6076a687da7d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Actor(MemoryActor, d4198fc6bd2576a8c03c067701000000)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5b39f3fc-225c-4792-bba2-6606efe733d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rm = RemoteMemory(actor_name='m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b0f7092b-a00e-46be-9f1d-b228fdbbe5aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = ChatOpenAI()\n",
    "chain = ConversationChain(\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    memory=rm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2b00f28e-8fda-41e2-9c03-eb4b4dc48bdf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: My name is Brian\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hello Brian, it's nice to meet you! How can I assist you today?\""
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(input='My name is Brian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0646a45d-133c-46e3-9312-508fa7121e13",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: My name is Brian\n",
      "AI: Hello Brian, it's nice to meet you! How can I assist you today?\n",
      "Human: Do you remember my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Yes, your name is Brian.'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(input='Do you remember my name?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b373f785-6146-4aae-9753-3e8b625cfd57",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: My name is Brian\\nAI: Hello Brian, it's nice to meet you! How can I assist you today?\\nHuman: Do you remember my name?\\nAI: Yes, your name is Brian.\"}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rm.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6f99b4-54ed-4e27-b6fe-59b815296fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f483f6ce-f74a-467d-a493-f352636ae2d1",
   "metadata": {},
   "source": [
    "## Using with a chat model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a7be5885-f154-4815-b488-c1b2d8b22914",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chat = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "99d463ba-8f8c-4898-9198-89a47480fb5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "memory.chat_memory.add_user_message('My name is Brian')\n",
    "memory.chat_memory.add_ai_message('Nice to meet you Brian, how can I help you?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "30b81476-9a0e-48e6-89cf-714e6a5b1e46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chain = ConversationChain(\n",
    "    llm=chat,\n",
    "    verbose=True,\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4a8e0620-ffc4-4007-806f-67d29a8bf918",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "[HumanMessage(content='My name is Brian', additional_kwargs={}), AIMessage(content='Nice to meet you Brian, how can I help you?', additional_kwargs={})]\n",
      "Human: What is my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Your name is Brian!'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(input='What is my name?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "83a4377e-d60f-4b78-a318-cc69282febad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatMessageHistory(messages=[HumanMessage(content='My name is Brian', additional_kwargs={}), AIMessage(content='Nice to meet you Brian, how can I help you?', additional_kwargs={}), HumanMessage(content='What is my name?', additional_kwargs={}), AIMessage(content='Your name is Brian.', additional_kwargs={})])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.chat_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "facc9abf-84d8-4375-aa6f-38fd416862a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: My name is Brian\n",
      "AI: Nice to meet you Brian, how can I help you?\n",
      "Human: What is my name?\n",
      "AI: Your name is Brian.\n",
      "Human: What is my last name\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I'm sorry Brian, but I do not have access to your last name. Would you like me to assist you with something else?\""
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(input='What is my last name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3c9933c1-f3e2-42c0-9971-5e2b49ad81fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatMessageHistory(messages=[HumanMessage(content='My name is Brian', additional_kwargs={}), AIMessage(content='Nice to meet you Brian, how can I help you?', additional_kwargs={}), HumanMessage(content='What is my name?', additional_kwargs={}), AIMessage(content='Your name is Brian.', additional_kwargs={}), HumanMessage(content='What is my last name', additional_kwargs={}), AIMessage(content=\"I'm sorry Brian, but I do not have access to your last name. Would you like me to assist you with something else?\", additional_kwargs={})])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.chat_memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cec6b96-6951-4bf5-9ac2-f7c0f3de3e79",
   "metadata": {},
   "source": [
    "## WindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fa8d59ea-d6a1-43bd-a3cf-1f73f3e4333f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f29609e6-0af5-4200-b753-b65c36321ccd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "memory = ConversationBufferWindowMemory(k=3, ai_prefix='Jupyter AI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "eee70fb3-c23a-4661-b38d-f73192e2b335",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = ChatOpenAI()\n",
    "chain = ConversationChain(\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "39ba4fc2-f28c-48f5-931a-4226fbef0ead",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised APIConnectionError: Error communicating with OpenAI: ('Connection aborted.', ConnectionResetError(54, 'Connection reset by peer')).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi, my name is Brian, what is your name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hello Brian, my name is OpenAI. I'm an artificial intelligence designed to assist with various tasks and answer questions. I'm pleased to meet you!\""
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(input='Hi, my name is Brian, what is your name?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4b4f7221-2c59-43d2-9662-42ceeeb287bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, my name is Brian, what is your name?\n",
      "Jupyter AI: Hello Brian, my name is OpenAI. I'm an artificial intelligence designed to assist with various tasks and answer questions. I'm pleased to meet you!\n",
      "Human: What is numpy?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Numpy is a Python library used for scientific computing and data analysis. It provides support for multidimensional arrays, mathematical functions, linear algebra, and more. It is widely used in data science, machine learning, and other scientific applications.'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(input='What is numpy?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "048a3fea-9211-4324-9282-aad569ea5beb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, my name is Brian, what is your name?\n",
      "Jupyter AI: Hello Brian, my name is OpenAI. I'm an artificial intelligence designed to assist with various tasks and answer questions. I'm pleased to meet you!\n",
      "Human: What is numpy?\n",
      "Jupyter AI: Numpy is a Python library used for scientific computing and data analysis. It provides support for multidimensional arrays, mathematical functions, linear algebra, and more. It is widely used in data science, machine learning, and other scientific applications.\n",
      "Human: ok great, how do I import numpy in python?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'To import numpy in Python, you can use the following code:\\n\\nimport numpy as np\\n\\nThis will import numpy and give it the alias \"np\" for easier use in your code.'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(input='ok great, how do I import numpy in python?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f00ead53-8ca2-4c18-af20-4ccadd190cf5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, my name is Brian, what is your name?\n",
      "Jupyter AI: Hello Brian, my name is OpenAI. I'm an artificial intelligence designed to assist with various tasks and answer questions. I'm pleased to meet you!\n",
      "Human: What is numpy?\n",
      "Jupyter AI: Numpy is a Python library used for scientific computing and data analysis. It provides support for multidimensional arrays, mathematical functions, linear algebra, and more. It is widely used in data science, machine learning, and other scientific applications.\n",
      "Human: ok great, how do I import numpy in python?\n",
      "Jupyter AI: To import numpy in Python, you can use the following code:\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "This will import numpy and give it the alias \"np\" for easier use in your code.\n",
      "Human: how do I create an empty array?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'To create an empty array in numpy, you can use the np.empty() function. The function takes the shape of the array as an argument and returns an array with uninitialized values. For example, to create a 2x3 array of zeros, you can use the following code:\\n\\nimport numpy as np\\n\\nempty_array = np.empty((2, 3))\\nprint(empty_array)\\n\\nThis will output:\\n\\n[[4.67296746e-307 1.69121096e-306 1.33511018e-306]\\n [6.23059726e-307 2.22522597e-307 1.42417221e-306]]'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(input='how do I create an empty array?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1014be3c-ca6d-4bf9-92ba-e83199d63b1b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(memory.chat_memory.messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d897f39c-af96-487c-93b1-177ce3e6030e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: What is numpy?\\nJupyter AI: Numpy is a Python library used for scientific computing and data analysis. It provides support for multidimensional arrays, mathematical functions, linear algebra, and more. It is widely used in data science, machine learning, and other scientific applications.\\nHuman: ok great, how do I import numpy in python?\\nJupyter AI: To import numpy in Python, you can use the following code:\\n\\nimport numpy as np\\n\\nThis will import numpy and give it the alias \"np\" for easier use in your code.\\nHuman: how do I create an empty array?\\nJupyter AI: To create an empty array in numpy, you can use the np.empty() function. The function takes the shape of the array as an argument and returns an array with uninitialized values. For example, to create a 2x3 array of zeros, you can use the following code:\\n\\nimport numpy as np\\n\\nempty_array = np.empty((2, 3))\\nprint(empty_array)\\n\\nThis will output:\\n\\n[[4.67296746e-307 1.69121096e-306 1.33511018e-306]\\n [6.23059726e-307 2.22522597e-307 1.42417221e-306]]'}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1c08bda6-2a48-42e1-b273-9d0a2a46d826",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: What is numpy?\n",
      "Jupyter AI: Numpy is a Python library used for scientific computing and data analysis. It provides support for multidimensional arrays, mathematical functions, linear algebra, and more. It is widely used in data science, machine learning, and other scientific applications.\n",
      "Human: ok great, how do I import numpy in python?\n",
      "Jupyter AI: To import numpy in Python, you can use the following code:\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "This will import numpy and give it the alias \"np\" for easier use in your code.\n",
      "Human: how do I create an empty array?\n",
      "Jupyter AI: To create an empty array in numpy, you can use the np.empty() function. The function takes the shape of the array as an argument and returns an array with uninitialized values. For example, to create a 2x3 array of zeros, you can use the following code:\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "empty_array = np.empty((2, 3))\n",
      "print(empty_array)\n",
      "\n",
      "This will output:\n",
      "\n",
      "[[4.67296746e-307 1.69121096e-306 1.33511018e-306]\n",
      " [6.23059726e-307 2.22522597e-307 1.42417221e-306]]\n"
     ]
    }
   ],
   "source": [
    "print(_['history'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ac1c52-ca9f-4a77-b021-3ea361a15374",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Prompt templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "12fa35e0-c047-4996-bb9a-d2109bb1296e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, MessagesPlaceholder, HumanMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a2e69b1f-39c0-47cf-abe0-34e69dead326",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(\"The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    HumanMessagePromptTemplate.from_template(\"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7127dc46-5d9f-4b49-96cc-d983558d187c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['history', 'input']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "17da315c-718d-48b9-b375-1c3067ecd7b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], output_parser=None, partial_variables={}, template='The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.', template_format='f-string', validate_template=True), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='history'),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], output_parser=None, partial_variables={}, template='{input}', template_format='f-string', validate_template=True), additional_kwargs={})]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a89319fa-61cf-4149-b1e1-ce0fa36da9b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "variable history should be a list of base messages, got My name is Brian",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mprompt_template\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_prompt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMy name is Brian\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mWhat is my name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Application Support/hatch/env/virtual/jupyter-ai-monorepo/geXHyXYD/jupyter-ai-monorepo/lib/python3.9/site-packages/langchain/prompts/chat.py:127\u001b[0m, in \u001b[0;36mBaseChatPromptTemplate.format_prompt\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mformat_prompt\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PromptValue:\n\u001b[0;32m--> 127\u001b[0m     messages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_messages\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ChatPromptValue(messages\u001b[38;5;241m=\u001b[39mmessages)\n",
      "File \u001b[0;32m~/Library/Application Support/hatch/env/virtual/jupyter-ai-monorepo/geXHyXYD/jupyter-ai-monorepo/lib/python3.9/site-packages/langchain/prompts/chat.py:186\u001b[0m, in \u001b[0;36mChatPromptTemplate.format_messages\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(message_template, BaseMessagePromptTemplate):\n\u001b[1;32m    181\u001b[0m     rel_params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    182\u001b[0m         k: v\n\u001b[1;32m    183\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    184\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m message_template\u001b[38;5;241m.\u001b[39minput_variables\n\u001b[1;32m    185\u001b[0m     }\n\u001b[0;32m--> 186\u001b[0m     message \u001b[38;5;241m=\u001b[39m \u001b[43mmessage_template\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_messages\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrel_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m     result\u001b[38;5;241m.\u001b[39mextend(message)\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Application Support/hatch/env/virtual/jupyter-ai-monorepo/geXHyXYD/jupyter-ai-monorepo/lib/python3.9/site-packages/langchain/prompts/chat.py:43\u001b[0m, in \u001b[0;36mMessagesPlaceholder.format_messages\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m value \u001b[38;5;241m=\u001b[39m kwargs[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariable_name]\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m---> 43\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     44\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvariable \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariable_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m should be a list of base messages, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     45\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     46\u001b[0m     )\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m value:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, BaseMessage):\n",
      "\u001b[0;31mValueError\u001b[0m: variable history should be a list of base messages, got My name is Brian"
     ]
    }
   ],
   "source": [
    "prompt_template.format_prompt(history='My name is Brian', input='What is my name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "414c17d1-dc5c-472c-b213-3bc3f9806840",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ChatPromptValue' from 'langchain.prompts' (/Users/brgrange/Library/Application Support/hatch/env/virtual/jupyter-ai-monorepo/geXHyXYD/jupyter-ai-monorepo/lib/python3.9/site-packages/langchain/prompts/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompts\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChatPromptValue\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'ChatPromptValue' from 'langchain.prompts' (/Users/brgrange/Library/Application Support/hatch/env/virtual/jupyter-ai-monorepo/geXHyXYD/jupyter-ai-monorepo/lib/python3.9/site-packages/langchain/prompts/__init__.py)"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b31c38-ea9b-4854-9383-db926b389a5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
