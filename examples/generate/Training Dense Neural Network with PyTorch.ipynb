{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5324abdd",
   "metadata": {},
   "source": [
    "# Training Dense Neural Network with PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce2e9ba",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1e8269",
   "metadata": {},
   "source": [
    "This notebook was created by [Jupyter AI](https://github.com/jupyterlab/jupyter-ai) with the following prompt:\n",
    "\n",
    "> A Jupyter notebook on training a dense neural network with 3 layers using PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03c0e8d",
   "metadata": {},
   "source": [
    "This Jupyter notebook covers the process of training a dense neural network with 3 layers using PyTorch. The notebook begins with importing necessary libraries and loading the dataset. Preprocessing the dataset and splitting it into training and validation sets is then performed. The architecture of the neural network is defined, followed by defining the loss function and optimizer. The notebook then goes on to train the neural network on the training set and validate it on the validation set. The performance of the model is evaluated on the test set and the accuracy is printed. Overall, this notebook provides a comprehensive guide to training a neural network using PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95c4ee9",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd9bb6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63eb467c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0b703e9",
   "metadata": {},
   "source": [
    "## Preparing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0753783a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the dataset\n",
    "X = dataset.iloc[:, :-1].values # Extract features (all columns except the last one)\n",
    "y = dataset.iloc[:, -1].values # Extract target (last column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311790fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the target variable\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597517ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbef2579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shapes of the training and validation sets\n",
    "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation set shape:\", X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288c7b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shapes of the training and validation sets\n",
    "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation set shape:\", X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea5cff6",
   "metadata": {},
   "source": [
    "## Defining the neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dbdf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network architecture\n",
    "class NeuralNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.layer1 = torch.nn.Linear(4, 10) # First layer with 4 input features and 10 output features\n",
    "        self.layer2 = torch.nn.Linear(10, 5) # Second layer with 10 input features and 5 output features\n",
    "        self.layer3 = torch.nn.Linear(5, 3) # Third layer with 5 input features and 3 output features\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.layer1(x)) # Pass input through first layer and apply ReLU activation function\n",
    "        x = torch.relu(self.layer2(x)) # Pass through second layer and apply ReLU activation function\n",
    "        x = self.layer3(x) # Pass through third layer without activation function\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057af6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the neural network\n",
    "model = NeuralNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6f61fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the neural network architecture\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8122dd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the neural network architecture\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4430b6b0",
   "metadata": {},
   "source": [
    "## Defining the loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46fc0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function and optimizer\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b958e6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function and optimizer\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11cd335",
   "metadata": {},
   "source": [
    "## Training the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de30c01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the neural network\n",
    "num_epochs = 1000\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    inputs = torch.Tensor(X_train).float()\n",
    "    targets = torch.Tensor(y_train).long()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, targets)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    train_losses.append(loss.item())\n",
    "    \n",
    "    # Validation phase\n",
    "    with torch.no_grad():\n",
    "        inputs = torch.Tensor(X_val).float()\n",
    "        targets = torch.Tensor(y_val).long()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        val_losses.append(loss.item())\n",
    "    \n",
    "    # Print the training and validation loss values for every 100 epochs\n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {train_losses[-1]:.4f}, Validation Loss: {val_losses[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2371315c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and validation loss curves\n",
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(val_losses, label='Validation loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a468053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and validation loss curves\n",
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(val_losses, label='Validation loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e0d55f",
   "metadata": {},
   "source": [
    "## Evaluating the performance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb72c861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the performance of the model on the test set\n",
    "# Load the test dataset\n",
    "url_test = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.test\" # Test dataset URL\n",
    "dataset_test = pd.read_csv(url_test, skiprows=1, names=names) # Load test dataset into a Pandas data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c7800a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the test dataset\n",
    "X_test = dataset_test.iloc[:, :-1].values # Extract features (all columns except the last one)\n",
    "y_test = dataset_test.iloc[:, -1].values # Extract target (last column)\n",
    "y_test = le.transform(y_test) # Encode the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98e1cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert test inputs and targets to PyTorch tensors\n",
    "inputs_test = torch.Tensor(X_test).float()\n",
    "targets_test = torch.Tensor(y_test).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f849708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "outputs_test = model(inputs_test) # Forward pass\n",
    "_, predicted = torch.max(outputs_test, 1) # Get the predicted class for each test input\n",
    "correct = (predicted == targets_test).sum().item() # Get the number of correctly predicted test inputs\n",
    "accuracy = correct / len(targets_test) # Compute the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113d5abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the accuracy of the model on the test set\n",
    "print(f\"Accuracy on the test set: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0064ac8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the accuracy of the model on the test set\n",
    "print(f\"Accuracy on the test set: {accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
